name: Build & Publish

on:
  push:
    branches: [main]
    paths:
      - 'packages/**/PKGBUILD'

env:
  BUCKET: aur-repo
  ENDPOINT: https://638815f23f9f434d94d64736c4e08175.r2.cloudflarestorage.com
  AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_KEY }}

jobs:
  list:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2
      - id: set-matrix
        run: |
          changed=$(git diff --name-only HEAD^..HEAD -- packages/*/PKGBUILD | xargs -r dirname | jq -R -s -c 'split("\n")[:-1]')
          echo "matrix=$changed" >> $GITHUB_OUTPUT

  build:
    needs: list
    if: needs.list.outputs.matrix != '[]'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        pkgdir: ${{ fromJson(needs.list.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v4

      # =====  编译 + 索引 + 上传 一条龙  =====
      - name: Build & repo-add & Push to R2
        run: |
          docker run --rm -v "$PWD":/src -w /src \
            -e BUCKET -e ENDPOINT -e AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY \
            archlinux:latest bash -ec '
              set -e
              pacman -Syu --noconfirm
              pacman -S --noconfirm base-devel sudo git pacman-contrib rclone
              useradd -m -G wheel build
              echo "build ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers
              chown -R build:build /src
              cd /src/${{ matrix.pkgdir }}

              # 1. 编译
              su build -c "makepkg --syncdeps --noconfirm --cleanbuild --skipinteg"

              # 2. 取架构
              arch=$(tar -xOf *.pkg.tar.zst .PKGINFO | grep "^arch = " | cut -d" " -f3)
              [ "$arch" = "any" ] && target="any" || target="x86_64"
              workdir="/tmp/repo-$target"
              mkdir -p "$workdir"

              # 3. 如果有旧 db 就拉回（空桶时静默跳过）
              rclone config create r2 s3 provider=Cloudflare \
                    access_key_id=$AWS_ACCESS_KEY_ID \
                    secret_access_key=$AWS_SECRET_ACCESS_KEY \
                    endpoint=$ENDPOINT \
                    --s3-no-check-bucket
              rclone copy "r2:$BUCKET/$target/$BUCKET.db.tar.gz"     "$workdir/" 2>/dev/null || true
              rclone copy "r2:$BUCKET/$target/$BUCKET.files.tar.gz" "$workdir/" 2>/dev/null || true

              # 4. 加入新包并更新索引
              cp *.pkg.tar.zst "$workdir/"
              repo-add -n -R "$workdir/$BUCKET.db.tar.gz" "$workdir"/*.pkg.tar.zst

              # 5. 推回 R2
              rclone copy "$workdir/" "r2:$BUCKET/$target/" --s3-no-check-bucket --progress
            '